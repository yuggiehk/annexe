<!DOCTYPE html>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="google-site-verification" content="0ahUKEwiTl96jlcL9AhUVN8AKHTMZAuUQPAgI">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>ANNEXE | Yuejiao Su</title>
    <meta name="author" content="Yuejiao Su">
    <meta name="description" content="ANNEXE: Unified Analyzing, Answering, and Pixel Grounding for Egocentric Interaction (CVPR 2025)">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css"
        integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css"
        integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css"
        integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css"
        href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media=""
        id="highlight_theme_light">
    <link rel="shortcut icon" href="/assets/img/favicon.ico">
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://reagan1311.github.io/locate/">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css"
        media="none" id="highlight_theme_dark">
    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
</head>

<body class="fixed-top-nav sticky-bottom-footer">
    <header>
        <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
            <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span
                        class="font-weight-bold">Gen </span>Li</a> <button class="navbar-toggler collapsed ml-auto"
                    type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav"
                    aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span
                        class="icon-bar bottom-bar"></span> </button>
                <div class="collapse navbar-collapse text-right" id="navbarNav">
                    <ul class="navbar-nav ml-auto flex-nowrap">
                        <li class="nav-item "> <a class="nav-link" href="/">about</a> </li>
                        <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li>
                        <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i
                                    class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li>
                    </ul>
                </div>
            </div>
        </nav>
    </header>
    <div class="container mt-5">
        <h2 align="center" class="font-weight-bold"> LOCATE: Localize and Transfer Object Parts for Weakly Supervised
            Affordance Grounding </h2>
        <p style="text-align: center;" class="font-weight-normal"> CVPR 2023 </p>
        <p style="text-align: center; font-weight: normal"> <a href="http://reagan1311.github.io" style="color: #0069d1"
                rel="external nofollow noopener" target="_blank"> Gen Li</a><sup>1</sup>  <a
                href="http://varunjampani.github.io" style="color: #0069d1" rel="external nofollow noopener"
                target="_blank"> Varun Jampani</a><sup>2</sup>  <a href="https://deqings.github.io/"
                style="color: #0069d1" rel="external nofollow noopener" target="_blank"> Deqing Sun</a><sup>2</sup>  <a
                href="https://laurasevilla.me" style="color: #0069d1" rel="external nofollow noopener" target="_blank">
                Laura Sevilla-Lara</a><sup>1</sup>  </p>
        <p style="text-align: center; font-weight: normal"> <sup>1</sup>University of Edinburgh   <sup>2</sup>Google
            Research   </p>
        <div class="column has-text-centered">
            <div class="publication-links"> <span class="link-block"> <a href="https://arxiv.org/abs/2303.09665"
                        target="_blank" class="external-link button is-normal is-rounded is-dark"
                        rel="external nofollow noopener"> <span class="icon"> <i class="fas fa-file-pdf"></i> </span>
                        <span>Paper</span> </a> </span> <span class="link-block"> <a href="/assets/pdf/LOCATE_supp.pdf"
                        target="_blank" class="external-link button is-normal is-rounded is-dark"> <span class="icon">
                            <i class="fas fa-file-pdf"></i> </span> <span>Supp</span> </a> </span> <span
                    class="link-block"> <a href="https://github.com/Reagan1311/LOCATE" target="_blank"
                        class="external-link button is-normal is-rounded is-dark" rel="external nofollow noopener">
                        <span class="icon"> <i class="fab fa-github"></i> </span> <span>Code</span> </a> </span> <span
                    class="link-block"> <a href="https://www.youtube.com/watch?v=RLHansdFxII" target="_blank"
                        class="external-link button is-normal is-rounded is-dark" rel="external nofollow noopener">
                        <span class="icon" style="text-decoration: none"> <i class="fas fa-video"></i> </span>
                        <span>Video</span> </a> </span> </div>
        </div>
        <h3> Abstract </h3>
        <p>Humans excel at acquiring knowledge through observation. For example, we can learn to use new tools by
            watching demonstrations. This skill is fundamental for intelligent systems to interact with the world. A key
            step to acquire this skill is to identify what part of the object affords each action, which is called
            affordance grounding. In this paper, we address this problem and propose a framework called LOCATE that can
            identify matching object parts across images, to transfer knowledge from images where an object is being
            used (exocentric images used for learning), to images where the object is inactive (egocentric ones used to
            test). To this end, we first find interaction areas and extract their feature embeddings. Then we learn to
            aggregate the embeddings into compact prototypes (human, object part, and background), and select the one
            representing the object part. Finally, we use the selected prototype to guide affordance grounding. We do
            this in a weakly supervised manner, learning only from image-level affordance and object labels. Extensive
            experiments demonstrate that our approach outperforms state-of-the-art methods by a large margin on both
            seen and unseen objects.</p>
        <center>
            <figure>
                <div id="projectid"> <img src="/assets/img/locate/problem_setting.gif" width="100%"> </div>
                <figcaption style="font-size: 90%; margin-top: 12px; text-align: left; font-weight: 400"> The problem
                    setting of the Weakly Supervised Affordance Grounding task. </figcaption>
            </figure>
        </center>
        <hr>
        <h3> Pipeline </h3>
        <center>
            <figure>
                <div id="projectid"> <img src="/assets/img/locate/pipeline.png" width="100%"> </div>
                <figcaption style="font-size: 90%; margin-top: 12px; text-align: left; font-weight: 400"> Overview of
                    the proposed LOCATE framework. It achieves part-level knowledge transfer in three steps: 1) locating
                    interaction regions with ψ<sub>cam</sub>, 2) object-part embedding selection with PartSelect, and 3)
                    part-level knowledge transfer with L<sub>cos</sub>. At test time, only the egocentric branch is
                    maintained. </figcaption>
            </figure>
        </center>
        <hr>
        <h3> Video Summary </h3>
        <center>
            <div class="embed-responsive embed-responsive-16by9" style="width: 95%"> <iframe
                    class="embed-responsive-item" src="https://www.youtube.com/embed/RLHansdFxII" frameborder="0"
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                    allowfullscreen=""></iframe> </div>
        </center>
        <hr>
        <h3> Qualitative Results </h3>
        <center>
            <figure>
                <div id="projectid"> <img src="/assets/img/locate/results.png" width="100%"> </div>
                <figcaption style="font-size: 90%; margin-top: 12px; text-align: left; font-weight: 400"> Qualitative
                    comparison between our approach and state-of-the-art affordance grounding methods (<a
                        href="https://arxiv.org/abs/1812.04558" rel="external nofollow noopener"
                        target="_blank">Hotspots [41]</a>, <a href="https://arxiv.org/abs/2203.09905"
                        rel="external nofollow noopener" target="_blank">Cross-view-AG [36]</a>, and <a
                        href="https://arxiv.org/abs/2208.13196" rel="external nofollow noopener"
                        target="_blank">Cross-view-AG+ [35]</a>). For the unseen setting, the displayed objects are not
                    in the training set. For example, the model learns where a motorcycle can be ridden in training, and
                    locates rideable area for the bicycle at test time. </figcaption>
            </figure>
        </center>
        <hr>
        <h3> Citation </h3>
        <div class="language-plaintext highlighter-rouge">
            <div class="highlight">
                <pre class="highlight"><code>@inproceedings{li:locate:2023,
    title = {LOCATE: Localize and Transfer Object Parts for Weakly Supervised Affordance Grounding},
    author = {Li, Gen and Jampani, Varun and Sun, Deqing and Sevilla-Lara, Laura},
    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    year={2023}
  }
  </code></pre>
            </div>
        </div>
    </div>
    <footer class="sticky-bottom mt-5">
        <div class="container"> © Copyright 2025 Gen Li. Last updated: May 09, 2025. </div>
    </footer>
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"
        integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js"
        integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js"
        integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js"
        integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
    <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js"
        integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
    <script defer src="/assets/js/zoom.js"></script>
    <script defer src="/assets/js/common.js"></script>
    <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
    <script async src="https://badge.dimensions.ai/badge.js"></script>
    <script type="text/javascript">window.MathJax = { tex: { tags: "ams" } };</script>
    <script defer type="text/javascript" id="MathJax-script"
        src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
    <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NYJ88YK0VS"></script>
    <script>function gtag() { window.dataLayer.push(arguments) } window.dataLayer = window.dataLayer || [], gtag("js", new Date), gtag("config", "G-NYJ88YK0VS");</script>
</body>

</html>
